<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Debugging Code World Models - Blog</title>
    <link rel="stylesheet" href="../styles/main.css?v=5">
    <link rel="stylesheet" href="../styles/post.css?v=20">
    <!-- KaTeX for math rendering -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"></script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            renderMathInElement(document.body, {
                delimiters: [
                    {left: "$$", right: "$$", display: true},
                    {left: "$", right: "$", display: false},
                    {left: "\\[", right: "\\]", display: true},
                    {left: "\\(", right: "\\)", display: false}
                ],
                throwOnError: false
            });
        });
    </script>
</head>
<body>
    <main>
        <article class="post-content">
            <div class="post-header">
                <h1>Debugging Code World Models</h1>
                <p class="post-authors">Babak Rahmani ¬∑ Julien Siems ¬∑ Riccardo Grazzi</p>
                <p class="post-meta">
                    <span class="post-date">January 2026</span>
                    <span class="reading-time">~15 min read</span>
                </p>
            </div>
            
            <!-- Report Tabs -->
            <div class="report-tabs">
                <a href="../assets/reports/cruxeval_failure_report.html" class="report-tab" target="_blank">
                    <span class="tab-label">CruxEval Report</span>
                    <span class="tab-arrow">‚Üó</span>
                </a>
                <a href="../assets/reports/humaneval_failure_report.html" class="report-tab" target="_blank">
                    <span class="tab-label">HumanEval Report</span>
                    <span class="tab-arrow">‚Üó</span>
                </a>
                <a href="../assets/reports/nesting_report.html" class="report-tab" target="_blank">
                    <span class="tab-label">Nesting Report</span>
                    <span class="tab-arrow">‚Üó</span>
                </a>
            </div>
            
            <div class="post-tags">
                <span class="tag">Code World Models</span>
                <span class="tag">State-Tracking</span>
                <span class="tag">Linear RNNs</span>
                <span class="tag">Transformers</span>
            </div>

            <div class="figure-container" style="margin-top: 2rem;">
                <div style="display: flex; justify-content: center; gap: 1.5rem; flex-wrap: wrap;">
                    <img src="../assets/images/gpt5_cwm_comparison_bar-1.png" alt="GPT-5 vs CWM accuracy comparison on S5 permutation tracking" style="max-width: 48%; height: auto;">
                    <img src="../assets/images/composition_accuracy_with_flattening.png" alt="Composition accuracy by depth" style="max-width: 48%; height: auto;">
                </div>
                <p class="figure-caption">
                    <strong>Figure 1:</strong> <strong>(Left)</strong> Accuracy on $S_5$ permutation tracking across sequence lengths (8‚Äì128 swaps). 
                    CWM baseline generates both commands and states; CWM+TF (teacher forcing) receives ground-truth commands 
                    and only predicts states. GPT-5 degrades rapidly while CWM+TF maintains high accuracy, showing the model 
                    can track state when given correct actions. 
                    <strong>(Right)</strong> Composition accuracy on nested string functions (depths 1‚Äì5). Observed accuracy 
                    falls far below the theoretical baseline (dashed) computed from atomic accuracy. 
                    Flattening nested calls into sequential assignments (red) provides modest improvement but cannot 
                    close the gap.
                </p>
            </div>

            <!-- Section 1: World Models -->
            <section id="introduction">
                <h2>1. World Models</h2>
                
                <p>
                    <strong>World models (WMs)</strong> are a framework for prediction (simulation) and planning: 
                    you learn a model of how an environment evolves, then you can "roll it forward" to see 
                    the result of an action. WMs were first popularized in images/videos, such as Genie <a href="#ref-genie">[1]</a> in game-like 
                    settings where an agent interacts with an environment; the promise is that the agent can 
                    learn new abilities by interacting with the learned simulator, enabling more open-ended 
                    behavior (e.g., exploration, long-horizon planning, skill acquisition).
                </p>

                <p>
                    Recently, there have been several works that treat language models trained on text as 
                    world models, including for text-based games <a href="#ref-plm">[3]</a>, general game playing <a href="#ref-ggp">[4]</a>, 
                    and code generation guided by MCTS <a href="#ref-mcts">[5]</a><a href="#ref-worldcoder">[6]</a>. 
                    The key difference from a standard language model is the <em>training interface</em>: 
                    an explicit <strong>action + state</strong> format. For example, a <strong>code world model (CWM)</strong> <a href="#ref-cwm">[2]</a> 
                    is trained on traces that look like:
                </p>

                <div class="notation-box">
                    <div class="notation-item">
                        <span class="notation-term action">action</span>
                        <span class="notation-equals">=</span>
                        <span class="notation-definition">‚ü®code / command‚ü©</span>
                    </div>
                    <div class="notation-item">
                        <span class="notation-term state">state</span>
                        <span class="notation-equals">=</span>
                        <span class="notation-definition">‚ü®runtime variable values‚ü©</span>
                    </div>
                </div>

                <p>
                    This turns code execution into a supervised "simulate the next state" problem. The CWM paper 
                    reports that this kind of training improves downstream performance on software-engineering 
                    style benchmarks (e.g., SWE-bench).
                </p>

                <h3>The Connection to State-Tracking</h3>
                <p>
                    This format is closely related to what the model-architecture community calls 
                    <strong>state tracking</strong>, often studied through finite-state automata and long-horizon 
                    length generalization <a href="#ref-merrill">[7]</a><a href="#ref-liu">[8]</a>. 
                    Theoretical work has shown that log-precision transformers face fundamental limitations 
                    in simulating finite automata <a href="#ref-merrill">[7]</a>, while recurrent architectures 
                    can represent these transition systems more naturally. Recent work on linear RNNs and 
                    state space models <a href="#ref-orvieto">[9]</a> demonstrates that careful initialization 
                    of recurrence eigenvalues enables reliable state tracking over long sequences. These 
                    findings suggest that the choice of architecture, and its alignment with the supervision 
                    structure, determines whether models can faithfully track latent state.
                </p>

                <p>
                    <strong>World modeling should solve state-tracking. But Transformers can't track state. 
                    CWM is a Transformer-based world model. </strong> Something has to give...
                </p>

                <div class="key-question">
                    <ul style="margin: 0; padding-left: 1.2rem;">
                        <li><strong>Where does it break?</strong> On which code patterns does CWM's state-tracking fail?</li>
                        <li><strong>Why?</strong> What mechanism explains both its successes and its failures?</li>
                        <li><strong>Can we fix it?</strong> Can we recover accuracy by engineering around the limitations?</li>
                        <li><strong>At what cost?</strong> What are the efficiency implications for training and inference?</li>
                    </ul>
                </div>

                <p>
                    In this post, we use a <strong>state-tracking lens</strong> to answer these questions.
                </p>
            </section>

            <!-- Section 2: Evaluation on Code Benchmarks -->
            <section id="evaluation">
                <h2>2. Evaluation on Code Benchmarks</h2>
                
                <p>
                    We evaluated CWM on two standard code execution benchmarks: <strong>CruxEval-O</strong> <a href="#ref-cruxeval">[11]</a>
                    (output prediction) and <strong>HumanEval</strong> <a href="#ref-humaneval">[12]</a> (function execution), as well as 
                    the <strong>Nesting</strong> dataset <a href="#ref-nesting">[10]</a> that probes compositional execution 
                    of nested string manipulation functions (e.g., <code>upper(replace(strip(x)))</code>). 
                    Table 1 summarizes the results.
                </p>

                <div class="comparison-table">
                    <p style="text-align: center; font-weight: bold; margin-bottom: 0.5rem;">Table 1: CWM accuracy on code execution benchmarks</p>
                    <table>
                        <thead>
                            <tr>
                                <th>Benchmark</th>
                                <th>Samples</th>
                                <th>Baseline Accuracy</th>
                                <th>After Intervention</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>CruxEval-O</td>
                                <td>800</td>
                                <td>85.1%</td>
                                <td><strong>90.4%</strong></td>
                            </tr>
                            <tr>
                                <td>HumanEval</td>
                                <td>723</td>
                                <td>91.4%</td>
                                <td><strong>‚Äî</strong></td>
                            </tr>
                            <tr style="border-top: 2px solid #ddd;">
                                <td>Nesting (depth=2)</td>
                                <td>100</td>
                                <td>75%</td>
                                <td><strong>78%</strong></td>
                            </tr>
                            <tr>
                                <td>Nesting (depth=3)</td>
                                <td>100</td>
                                <td>58%</td>
                                <td><strong>63%</strong></td>
                            </tr>
                            <tr>
                                <td>Nesting (depth=4)</td>
                                <td>100</td>
                                <td>39%</td>
                                <td><strong>43%</strong></td>
                            </tr>
                            <tr>
                                <td>Nesting (depth=5)</td>
                                <td>100</td>
                                <td>25%</td>
                                <td><strong>28%</strong></td>
                            </tr>
                        </tbody>
                    </table>
                </div>

                <p>
                    These baselines are strong but reveal systematic failure patterns. Error analysis 
                    (detailed in the <a href="../assets/reports/cruxeval_failure_report.html" target="_blank">CruxEval</a>, 
                    <a href="../assets/reports/humaneval_failure_report.html" target="_blank">HumanEval</a>, and 
                    <a href="../assets/reports/nesting_report.html" target="_blank">Nesting</a> reports) identifies three primary failure modes: 
                    <strong>compositionality</strong> (nested expressions hiding intermediate values), 
                    <strong>tokenization discontinuity</strong> (string operations breaking token boundaries), 
                    and <strong>trace truncation</strong> (loops generating traces that exceed the 32K token limit). 
                    We examine each below.
                </p>

                <p>
                    <strong>Figure 2</strong> illustrates the first two challenges and a potential resolution strategy. 
                    On the left, nested function calls hide intermediate values that CWM never sees during trace generation. 
                    On the right, string operations require character-level iteration that changes tokenization entirely. 
                    In both cases, <em>decomposing</em> the expression into explicit steps can expose these hidden states, 
                    restoring the dense supervision CWM relies on. We explore these interventions in <a href="#interventions">Section 4</a>.
                </p>

                <div class="transformation-figure">
                    <!-- Composition Panel -->
                    <div class="transformation-panel">
                        <div class="transformation-panel-header composition">
                            üîó Composition
                        </div>
                        <div class="transformation-content">
                            <div class="transform-block original-block">
                                <div class="transform-label original">Original Code</div>
                                <div class="transform-code">
<span class="variable">nums</span> = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>]
<span class="variable">n</span> = <span class="number">2</span>
<span class="variable">output</span> = []
<span class="variable">output</span>.<span class="function">append</span>((<span class="variable">nums</span>.<span class="function">count</span>(<span class="variable">n</span>), <span class="variable">n</span>))
                                </div>
                            </div>
                            
                            <div class="transform-arrow">
                                <svg viewBox="0 0 24 24" fill="currentColor"><path d="M12 4l-1.41 1.41L16.17 11H4v2h12.17l-5.58 5.59L12 20l8-8z"/></svg>
                            </div>
                            
                            <div class="transform-block transformed-block">
                                <div class="transform-label transformed">Decomposed</div>
                                <div class="transform-code">
<span class="temp-var">_t0</span> = <span class="variable">nums</span>.<span class="function">count</span>(<span class="variable">n</span>)  <span class="comment"># hidden!</span>
<span class="temp-var">_t1</span> = (<span class="temp-var">_t0</span>, <span class="variable">n</span>)           <span class="comment"># hidden!</span>
<span class="variable">output</span>.<span class="function">append</span>(<span class="temp-var">_t1</span>)
                                </div>
                            </div>
                            
                            <div class="transform-insight">
                                <strong>Issue:</strong> Nested calls hide intermediate values 
                                (<code>_t0</code>, <code>_t1</code>) ‚Äî effective reveal spacing &gt; 1
                            </div>
                        </div>
                    </div>

                    <!-- String Manipulation Panel -->
                    <div class="transformation-panel">
                        <div class="transformation-panel-header string-manip">
                            üìù String Manipulation
                        </div>
                        <div class="transformation-content">
                            <div class="transform-block original-block">
                                <div class="transform-label original">Original Code</div>
                                <div class="transform-code">
<span class="variable">text</span> = <span class="string">"abracadabra"</span>
<span class="variable">char</span> = <span class="string">"c"</span>
<span class="variable">pos</span> = <span class="variable">text</span>.<span class="function">index</span>(<span class="variable">char</span>)
                                </div>
                            </div>
                            
                            <div class="transform-arrow">
                                <svg viewBox="0 0 24 24" fill="currentColor"><path d="M12 4l-1.41 1.41L16.17 11H4v2h12.17l-5.58 5.59L12 20l8-8z"/></svg>
                            </div>
                            
                            <div class="transform-block transformed-block">
                                <div class="transform-label transformed">Explicit Loop</div>
                                <div class="transform-code">
<span class="temp-var">_t0</span> = <span class="function">list</span>(<span class="variable">text</span>)
<span class="temp-var">_t1</span> = <span class="number">-1</span>
<span class="keyword">for</span> <span class="temp-var">_t2</span> <span class="keyword">in</span> <span class="function">range</span>(<span class="function">len</span>(<span class="temp-var">_t0</span>)):
    <span class="keyword">if</span> <span class="temp-var">_t0</span>[<span class="temp-var">_t2</span>] == <span class="variable">char</span>:
        <span class="temp-var">_t1</span> = <span class="temp-var">_t2</span>
        <span class="keyword">break</span>
<span class="variable">pos</span> = <span class="temp-var">_t1</span>
                                </div>
                            </div>
                            
                            <div class="transform-insight">
                                <strong>Issue:</strong> String‚Üílist conversion changes tokenization; 
                                loop iterations create many hidden states
                            </div>
                        </div>
                    </div>
                </div>

                <p class="figure-caption" style="text-align: center; margin-top: -0.5rem;">
                    <strong>Figure 2:</strong> Two challenges in real code and potential decomposition strategies. 
                    <strong>Left:</strong> Composition hides intermediate results in nested expressions. 
                    <strong>Right:</strong> String manipulation requires tokenization changes and implicit iteration.
                </p>

                <h3>2.1 Challenge: Compositionality</h3>
                
                <p>
                    As shown in Figure 2 (left), when commands are <em>composed</em> (nested within other commands 
                    or combined into compound expressions), the reveal spacing effectively becomes greater than one. 
                    The intermediate states between sub-operations are never exposed to the model.
                </p>

                <p>
                    <strong>Experimental setup:</strong> Using the library of 25 deterministic 
                    string-manipulation functions from the Nesting dataset <a href="#ref-nesting">[10]</a>, 
                    we designed prompts for CWM and first evaluated on atomic (depth-1) calls. 
                    We selected the 15 functions achieving ‚â•90% atomic accuracy (average: 95.3%), 
                    then generated 100 test samples per depth for compositions from depth 1 to 5 
                    (e.g., depth 3 = <code>func_A(func_B(func_C(x)))</code>).
                </p>

                <div class="figure-container">
                    <img src="../assets/images/atomic_all25_accuracy_report.png" alt="Atomic Function Accuracy" style="max-width: 100%;">
                    <p class="figure-caption">
                        <strong>Figure 3:</strong> CWM atomic (depth-1) accuracy across all 25 string-manipulation functions. 
                        Functions achieving ‚â•90% accuracy (above green dashed line) were selected for the composition 
                        experiment, yielding 15 high-accuracy functions with average accuracy of 95.3%.
                    </p>
                </div>

                <p>
                    <strong>Results:</strong> At depth 5, observed accuracy (25%) is 
                    <strong>50 percentage points below</strong> the theoretical baseline (78.6%) 
                    computed from atomic accuracy (0.953‚Åµ). This gap grows super-linearly with depth 
                    (Figure 1, right), indicating compositional execution introduces errors beyond simple error propagation.
                </p>

                <h3>2.2 Challenge: Trace Truncation</h3>
                <p>
                    Dense state supervision has a hidden cost: <strong>token explosion</strong>. 
                    When code contains loops, each iteration generates a full state snapshot. 
                    For O(n¬≤) algorithms or large inputs, traces can exceed the 32K token limit, 
                    causing truncation before the final output is reached.
                </p>
                <p>
                    In CruxEval, 6 samples failed because their traces exceeded the 32K token limit. 
                    An additional 17 samples failed on loop/counter errors, where the model lost 
                    track during long iterations even without truncation. Together, these reveal 
                    a fundamental tension: the same dense supervision that enables reliable 
                    state-tracking also creates traces too long to process.
                </p>

                <h3>2.3 Challenge: Tokenization Discontinuity</h3>
                <p>
                    String manipulation creates a challenge unrelated to supervision density: 
                    <strong>minor semantic changes can cause dramatic shifts in tokenization</strong>. 
                    A single character edit might transform a string from one token into five or more, 
                    as illustrated in Figure 4.
                </p>

                <div class="tokenization-figure">
                    <div class="tokenization-figure-title">Tokenization Discontinuity in String State-Tracking</div>
                    
                    <!-- Initial State -->
                    <div class="tokenization-row">
                        <div class="tokenization-label">Initial State:</div>
                        <div class="tokenization-content">
                            <div class="state-box">s = "abcdefghijklmnopqrstuvwxyz"</div>
                        </div>
                    </div>
                    
                    <div class="tokenization-row">
                        <div class="tokenization-label">Tokenization:</div>
                        <div class="tokenization-content">
                            <span class="token blue">[alphabet_26]</span>
                            <span class="token-count blue">1 token</span>
                        </div>
                    </div>
                    
                    <!-- Edit 1 -->
                    <div class="edit-marker">
                        <span class="edit-badge">1</span>
                        <span class="edit-text">Replace <code>'x'</code> ‚Üí <code>'X'</code></span>
                    </div>
                    
                    <div class="tokenization-row">
                        <div class="tokenization-label">New State:</div>
                        <div class="tokenization-content">
                            <div class="state-box">s = "abcdefghijklmnopqrstuvw<span class="highlight-char">X</span>yz"</div>
                        </div>
                    </div>
                    
                    <div class="tokenization-row">
                        <div class="tokenization-label">Tokenization:</div>
                        <div class="tokenization-content">
                            <span class="token orange">[abcdefghijklmnop]</span>
                            <span class="token orange">[qrst]</span>
                            <span class="token orange">[uvw]</span>
                            <span class="token orange">[X]</span>
                            <span class="token orange">[yz]</span>
                            <span class="token-count orange">5 tokens</span>
                        </div>
                    </div>
                    
                    <!-- Edit 2 -->
                    <div class="edit-marker">
                        <span class="edit-badge">2</span>
                        <span class="edit-text">Insert space at position 13</span>
                    </div>
                    
                    <div class="tokenization-row">
                        <div class="tokenization-label">New State:</div>
                        <div class="tokenization-content">
                            <div class="state-box">s = "abcdefghijklm<span class="highlight-char"> </span>nopqrstuvw<span class="highlight-char">X</span>yz"</div>
                        </div>
                    </div>
                    
                    <div class="tokenization-row">
                        <div class="tokenization-label">Tokenization:</div>
                        <div class="tokenization-content">
                            <span class="token green">[abcdefghijkl]</span>
                            <span class="token green">[m]</span>
                            <span class="token green">[ nop]</span>
                            <span class="token green">[qrst]</span>
                            <span class="token green">[uvw]</span>
                            <span class="token green">[X]</span>
                            <span class="token green">[yz]</span>
                            <span class="token-count green">7 tokens</span>
                        </div>
                    </div>
                </div>

                <p class="figure-caption" style="text-align: center; margin-top: -0.5rem;">
                    <strong>Figure 4:</strong> Tokenization discontinuity in string state-tracking. 
                    Minor edits (changing one character, inserting a space) cause radical changes 
                    in BPE token segmentation‚Äîfrom a single token to 5‚Äì7 tokens with entirely different boundaries. 
                    This makes string operations unpredictable for the model.
                </p>

                <p>
                    This is problematic for state-tracking: two strings that differ by a single character 
                    may have completely different token representations. The model cannot rely on 
                    surface-level similarity to predict the next state, making string operations 
                    a consistent source of errors.
                </p>

                <div class="takeaway-box">
                    <strong>Key Insight:</strong> These challenges have different roots. 
                    <strong>Compositionality</strong> and <strong>trace truncation</strong> are both 
                    consequences of dense supervision: the first creates hidden states, the second 
                    creates traces too long to process. <strong>Tokenization discontinuity</strong> 
                    is a separate problem with how BPE tokenizers represent strings, independent of 
                    supervision strategy.
                </div>
            </section>

            <!-- Section 3: State-Tracking -->
            <section id="state-tracking">
                <h2>3. A State-Tracking Lens</h2>
                
                <p>
                    Why does CWM succeed at state-tracking? The answer 
                    lies in its training format: <strong>dense state supervision</strong>. CWM tracks 
                    the state of <em>all variables after each command</em>‚Äîwhat we call 
                    <strong>reveal spacing = 1</strong>. Every operation is followed by a complete 
                    state snapshot, creating extremely dense supervision signal.
                </p>

                <p>
                    This raises a natural question: <em>can we achieve reliable state-tracking with 
                    sparser supervision?</em> To answer this, we need a controlled benchmark that 
                    isolates state-tracking from other code complexities.
                </p>

                <h3>3.1 The Shell Game Benchmark</h3>
                <p>
                    Imagine the classic shell game: three cups labeled A, B, C contain objects 1, 2, 3. 
                    A dealer shuffles them by swapping pairs of cups, and you must track which object ends 
                    up where. This is exactly what state-tracking requires: maintaining a mental model 
                    of system state through a sequence of operations.
                </p>
                
                <p>
                    $S_n$ in code can be constructed using a variable assignment problem where $n$ variables 
                    are initialized with random numbers and then have their values swapped in different commands. 
                    We can use print statements for partial reveal that could be used as supervision signals.
                </p>

                <div class="figure-container">
                    <img src="../assets/images/s3_s3-code-1.png?v=2" alt="S3 Shell Game and Code Implementation" style="max-width: 100%;">
                    <p class="figure-caption">
                        <strong>Figure 5:</strong> <strong>(Left)</strong> The shell game with three cups representing 
                        $S_3$ permutations: each swap changes which object is under which cup. 
                        <strong>(Right)</strong> The equivalent $S_n$ problem as Python code: variable assignments 
                        and swaps mirror the cup movements, where tracking the final values requires 
                        faithful state-tracking through each operation.
                    </p>
                </div>

                <h3>3.2 Evaluation Setup: GPT-5 vs CWM</h3>
                <p>
                    We evaluated both GPT-5 and CWM on $S_5$ permutation sequences with varying lengths: 
                    $N \in \{8, 16, 32, 64, 128\}$ swap operations (Figure 1, left). The task: predict the final values 
                    of all five variables.
                </p>

                <div class="box-red">
                    <strong>GPT-5 Setup:</strong> We use a structured chat format with a system prompt 
                    instructing the model to act as a Python code execution tracer. The model outputs 
                    final values in the format <code>a=X,b=X,c=X,d=X,e=X</code>. We use a maximum token 
                    limit of 16,384 and evaluate via exact string matching.
                    
                    <details class="prompt-details">
                        <summary>View Full Prompts</summary>
                        <div class="prompt-content">
                            <div class="prompt-box system-prompt">
                                <h5>System Prompt</h5>
                                <p>You are a Python code execution tracer. Your task is to trace through Python code that performs variable assignments and swaps, then determine the final values of ALL variables.</p>
                                
                                <p><strong>## Task Description</strong></p>
                                <p>Given a Python function that:</p>
                                <ol>
                                    <li>Initializes 5 variables (a, b, c, d, e) with integer values</li>
                                    <li>Performs a series of simultaneous variable swaps (e.g., <code>a, b, c, d, e = c, e, b, a, d</code>)</li>
                                </ol>
                                <p>You must trace through all the operations step by step and provide the final values of ALL five variables.</p>
                                
                                <p><strong>## Example</strong></p>
                                <p>Code:</p>
<pre><code>def execute_repl_trace():
    a = 1
    b = 2
    c = 3
    d = 4
    e = 5
    a, b, c, d, e = c, e, b, a, d
    a, b, c, d, e = e, b, c, d, a

def main():
    execute_repl_trace()</code></pre>
                                <p>Step-by-step trace:</p>
                                <ol>
                                    <li>Initial: a=1, b=2, c=3, d=4, e=5</li>
                                    <li>After <code>a, b, c, d, e = c, e, b, a, d</code>: a=3, b=5, c=2, d=1, e=4</li>
                                    <li>After <code>a, b, c, d, e = e, b, c, d, a</code>: a=4, b=5, c=2, d=1, e=3</li>
                                </ol>
                                <p>Answer: <code>a=4,b=5,c=2,d=1,e=3</code></p>
                                
                                <p><strong>## Instructions</strong></p>
                                <ul>
                                    <li>Trace through each assignment carefully</li>
                                    <li>Remember that tuple unpacking in Python happens simultaneously (all right-hand values are evaluated before any assignment)</li>
                                    <li>Provide the final values of ALL variables in the format: <code>a=X,b=X,c=X,d=X,e=X</code></li>
                                    <li>Do not include any explanation, just the comma-separated values</li>
                                </ul>
                            </div>
                            
                            <div class="prompt-box user-prompt">
                                <h5>User Prompt (Example with 8 swap operations)</h5>
                                <p>Trace through the following Python code and provide the final values of ALL variables.</p>
<pre><code>def execute_repl_trace():
    """Execute the REPL trace operations."""
    a = 8
    b = 4
    c = 7
    d = 8
    e = 7
    a, b, c, d, e = c, e, b, a, d
    a, b, c, d, e = e, b, c, d, a
    a, b, c, d, e = b, e, a, c, d
    a, b, c, d, e = a, b, e, d, c
    a, b, c, d, e = b, c, e, a, d
    a, b, c, d, e = e, a, c, b, d
    a, b, c, d, e = a, e, c, b, d
    a, b, c, d, e = b, d, e, c, a

def main():
    execute_repl_trace()</code></pre>
                                <p>What are the final values of all variables? Provide in the format: <code>a=X,b=X,c=X,d=X,e=X</code></p>
                            </div>
                        </div>
                    </details>
                </div>

                <div class="box-gray" style="margin-top: 1rem;">
                    <strong>CWM Setup:</strong> Uses the model's native trace format with specialized 
                    tokens (<code>&lt;|trace_context_start|&gt;</code>, <code>&lt;|frame_sep|&gt;</code>, 
                    <code>&lt;|action_sep|&gt;</code>). Unlike GPT-5 which only predicts final values, 
                    CWM generates a complete execution trace with explicit variable states in JSON format 
                    at each step.
                    
                    <details class="prompt-details">
                        <summary>View Full Format</summary>
                        <div class="prompt-content">
                            <div class="prompt-box cwm-input-prompt">
                                <h5>CWM Input Format</h5>
<pre><code>&lt;|begin_of_text|&gt;&lt;|trace_context_start|&gt;
def execute_repl_trace():
    """Execute the REPL trace operations."""
    a = 8
    b = 4
    c = 7
    d = 8
    e = 7
    a, b, c, d, e = c, e, b, a, d
    a, b, c, d, e = e, b, c, d, a
    a, b, c, d, e = b, e, a, c, d
    a, b, c, d, e = a, b, e, d, c
    a, b, c, d, e = b, c, e, a, d
    a, b, c, d, e = e, a, c, b, d
    a, b, c, d, e = a, e, c, b, d
    a, b, c, d, e = b, d, e, c, a
    print(f"c = {c}")

def main(): # &lt;&lt; START_OF_TRACE
    execute_repl_trace()
&lt;|frame_sep|&gt;</code></pre>
                            </div>
                            
                            <div class="prompt-box cwm-output-prompt">
                                <h5>CWM Output Format (Execution Trace)(abbreviated)</h5>
<pre><code>&lt;|call_sep|&gt;{}&lt;|action_sep|&gt;def main(): # &lt;&lt; START_OF_TRACE&lt;|frame_sep|&gt;
&lt;|call_sep|&gt;{"a":8,"b":4,"c":7,"d":8,"e":7}&lt;|action_sep|&gt;def execute_repl_trace():&lt;|frame_sep|&gt;
&lt;|line_sep|&gt;{"a":7,"b":4,"c":8,"d":8,"e":7}&lt;|action_sep|&gt;a, b, c, d, e = c, e, b, a, d&lt;|frame_sep|&gt;
...
&lt;|line_sep|&gt;{"a":7,"b":7,"c":8,"d":8,"e":4}&lt;|action_sep|&gt;print(f"c = {c}")&lt;|frame_sep|&gt;
&lt;|return_sep|&gt;{"a":7,"b":7,"c":8,"d":8,"e":4}&lt;|action_sep|&gt;print(f"c = {c}")&lt;|arg_sep|&gt;"None"&lt;|frame_sep|&gt;</code></pre>
                            </div>
                        </div>
                    </details>
                </div>

                <h3>3.3 CWM Hallucinates Commands</h3>
                
                <p>
                    As sequence length increases, CWM's accuracy drops. But <em>why</em>? Inspecting 
                    the errors reveals a surprising failure mode: <strong>the model hallucinates commands</strong>.
                </p>

                <p>
                    Rather than making small mistakes in state updates, CWM often generates an 
                    <em>incorrect next command</em>, predicting a swap that wasn't in the original 
                    sequence. Once this happens, all subsequent states become wrong because they're 
                    computed from a corrupted history (Figure 6).
                </p>

                <div class="figure-container">
                    <div class="comparison-side-by-side">
                        <div class="comparison-panel-left">
                            <h4>CWM Baseline</h4>
                            <div class="code-line" style="margin-bottom: 0.5rem;"><strong>Prompt:</strong></div>
                            <div class="code-line">a, b, c = 6, 6, 8</div>
                            <div class="code-line">a, b, c = b, c, a</div>
                            <div class="code-line" style="margin-bottom: 0.75rem;">a, b, c = b, a, c</div>
                            <div class="code-line" style="margin-bottom: 0.5rem;"><strong>Completion:</strong></div>
                            <div class="code-line"><span class="comment">&lt;|frame_sep|&gt;</span> {"a": 6, "b": 6, "c": 8}</div>
                            <div class="code-line"><span class="comment">&lt;|action_sep|&gt;</span> a, b, c = b, c, a</div>
                            <div class="code-line"><span class="comment">&lt;|frame_sep|&gt;</span> {"a": 6, "b": 8, "c": 6}</div>
                            <div class="code-line"><span class="comment">&lt;|action_sep|&gt;</span> a, b, c = <span class="highlight-box highlight-red">c, a, b</span> <span class="hallucinated">‚Üê hallucinated!</span></div>
                            <div class="code-line"><span class="comment">&lt;|frame_sep|&gt;</span> {"a": 6, "b": 6, "c": 8} ‚ùå</div>
                        </div>
                        <div class="comparison-panel-right">
                            <h4>CWM + Teacher Forcing</h4>
                            <div class="code-line" style="margin-bottom: 0.5rem;"><strong>Prompt:</strong></div>
                            <div class="code-line">a, b, c = 6, 6, 8</div>
                            <div class="code-line">a, b, c = b, c, a</div>
                            <div class="code-line" style="margin-bottom: 0.75rem;">a, b, c = b, a, c</div>
                            <div class="code-line" style="margin-bottom: 0.5rem;"><strong>Completion:</strong></div>
                            <div class="code-line"><span class="comment">&lt;|frame_sep|&gt;</span> {"a": 6, "b": 6, "c": 8}</div>
                            <div class="code-line"><span class="comment">&lt;|action_sep|&gt;</span> a, b, c = b, c, a</div>
                            <div class="code-line"><span class="comment">&lt;|frame_sep|&gt;</span> {"a": 6, "b": 8, "c": 6}</div>
                            <div class="code-line"><span class="comment">&lt;|action_sep|&gt;</span> a, b, c = <span class="highlight-box highlight-green">b, a, c</span> <span class="correct">‚Üê forced</span></div>
                            <div class="code-line"><span class="comment">&lt;|frame_sep|&gt;</span> {"a": 8, "b": 6, "c": 6} ‚úì</div>
                        </div>
                    </div>
                    <p class="figure-caption">
                        <strong>Figure 6:</strong> Action hallucination in CWM. <strong>(Left)</strong> Baseline: the model hallucinates 
                        command 2 (<code>c, a, b</code> instead of <code>b, a, c</code>), producing incorrect state. 
                        <strong>(Right)</strong> Teacher forcing: injecting ground-truth commands at each step yields correct state, 
                        demonstrating the model can track state when given correct actions.
                    </p>
                </div>

                <h3>3.4 Teacher Forcing: CWM Can Track State</h3>
                <p>
                    To decouple command generation from state tracking, we use <strong>teacher forcing</strong>: 
                    we feed the model the correct commands at each step, and only ask it to predict the 
                    resulting state. With teacher forcing, the correct intermediate state is injected after 
                    each command, breaking the error chain.
                </p>

                <p>
                    With teacher forcing, CWM maintains high accuracy even at 128 commands! This mechanism 
                    explains the large accuracy gap observed at longer trace lengths: <strong>at 64+ commands, 
                    baseline accuracy drops to 0% while teacher forcing maintains ~90%</strong>.
                </p>

                <p>
                    This tells us that <em>when commands are correct, the model can reliably propagate state 
                    over long horizons</em>. The dominant failure in the baseline setting is generating 
                    incorrect commands, not an inability to update state.
                </p>

                <div class="takeaway-box">
                    <strong>Key Insight:</strong> CWM failures on long sequences are dominated by 
                    <em>action hallucination</em> (producing incorrect commands), not state-tracking 
                    errors. Teacher forcing isolates state propagation and shows the model can track 
                    state reliably when given correct actions.
                </div>
            </section>

            <!-- Subsection 3.5: Dense Supervision -->
                <h3>3.5 Dense Supervision: Mechanism and Trade-offs</h3>
                
                <p>
                    The teacher forcing results confirm it: CWM's state-tracking ability comes from 
                    dense supervision, not architectural innovation. With reveal spacing = 1, the model 
                    <em>never has to track state for more than one step</em>. The explicit state 
                    reveals act as "checkpoints" that reset any accumulated error.
                </p>

                <div class="comparison-table">
                    <p style="text-align: center; font-weight: bold; margin-bottom: 0.5rem;">Table 2: Supervision density comparison</p>
                    <table>
                        <thead>
                            <tr>
                                <th>Approach</th>
                                <th>Reveal Spacing</th>
                                <th>Supervision Density</th>
                                <th>Token Cost</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>Standard LLM</td>
                                <td>‚àû (no reveals)</td>
                                <td>None</td>
                                <td>Low</td>
                            </tr>
                            <tr>
                                <td>Sparse reveals</td>
                                <td>4-8</td>
                                <td>Low</td>
                                <td>Medium</td>
                            </tr>
                            <tr style="background: #d4edda;">
                                <td><strong>CWM</strong></td>
                                <td><strong>1</strong></td>
                                <td><strong>Maximum</strong></td>
                                <td>High</td>
                            </tr>
                        </tbody>
                    </table>
                </div>

                <h3>3.6 The Trade-off</h3>
                <p>
                    Dense supervision works, but it comes at a cost:
                </p>
                <ul>
                    <li><strong>Training:</strong> Requires execution traces with full state dumps, which are expensive to collect</li>
                    <li><strong>Inference:</strong> Generates many tokens for state representations, making it slower and more expensive</li>
                    <li><strong>Brittleness:</strong> When state reveals become sparse (e.g., nested function calls), the model struggles</li>
                </ul>

                <div class="key-question">
                    <strong>The deeper question:</strong> Can we achieve reliable state-tracking 
                    with <em>sparser</em> supervision? This is where architecture starts to matter...
                </div>

                <h3>3.7 Architecture Matters for Sparse Supervision</h3>
                
                <p>
                    CWM's success with dense supervision (reveal spacing = 1) raises a natural question: 
                    what happens when we can't afford such dense state reveals? This is where 
                    <strong>architecture</strong> becomes critical.
                </p>

                <p>
                    We trained models from scratch on $S_5$ permutation traces with varying reveal 
                    spacings, comparing Transformers against linear RNNs with different eigenvalue ranges (Table 3):
                </p>

                <div class="comparison-table">
                    <p style="text-align: center; font-weight: bold; margin-bottom: 0.5rem;">Table 3: Architecture performance under sparse supervision</p>
                    <table>
                        <thead>
                            <tr>
                                <th>Architecture</th>
                                <th>Reveal Spacing = 1</th>
                                <th>Reveal Spacing = 4</th>
                                <th>Reveal Spacing = 8</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>Transformer</td>
                                <td>‚úÖ Good</td>
                                <td>‚ö†Ô∏è Degrades</td>
                                <td>‚ùå Fails</td>
                            </tr>
                            <tr>
                                <td>DeltaNet [0,1]</td>
                                <td>‚úÖ Good</td>
                                <td>‚ö†Ô∏è Degrades</td>
                                <td>‚ùå Fails</td>
                            </tr>
                            <tr style="background: #d4edda;">
                                <td><strong>DeltaNet [-1,1]</strong></td>
                                <td>‚úÖ Good</td>
                                <td>‚úÖ Good</td>
                                <td>‚úÖ Good</td>
                            </tr>
                        </tbody>
                    </table>
                </div>

                <p>
                    The key finding: <strong>DeltaNet with extended eigenvalues [-1,1]</strong> can 
                    learn state-tracking even with sparse supervision, and extrapolates to longer 
                    sequences than seen during training. Transformers and standard DeltaNet [0,1] 
                    both collapse as reveal spacing increases.
                </p>

                <div class="takeaway-box">
                    <strong>Takeaway:</strong> Architecture determines whether state-tracking 
                    generalizes under sparse supervision. CWM succeeds by avoiding this challenge 
                    entirely (dense reveals), but more efficient approaches require architectures 
                    designed for state-tracking.
                </div>
            </section>

            <!-- Section 4: Interventions -->
            <section id="interventions">
                <h2>4. Interventions</h2>
                
                <p>
                    Given the identified challenges, we tested targeted code transformations to 
                    expose hidden intermediate states. These interventions aim to restore the 
                    dense supervision that CWM relies on.
                </p>

                <h3>4.1 Expression Decomposition (CruxEval)</h3>
                <p>
                    We decomposed nested expressions into sequential assignments with explicit 
                    temporary variables, exposing intermediate values. For example, 
                    <code>output.append((nums.count(n), n))</code> becomes three separate lines 
                    with <code>_t0 = nums.count(n)</code>, <code>_t1 = (_t0, n)</code>, etc.
                </p>
                <p>
                    <strong>Result:</strong> Of 119 failed samples, <strong>37 were recovered</strong> 
                    (31% recovery rate), improving accuracy from 85.1% to 89.8% (+4.7pp).
                </p>

                <h3>4.2 String Decomposition (CruxEval)</h3>
                <p>
                    For single-character string operations (e.g., <code>text.index(char)</code>), 
                    we converted to explicit character-level loops. This makes each character 
                    position visible during trace generation, bypassing BPE tokenization issues.
                </p>
                <p>
                    <strong>Result:</strong> An additional <strong>5 unique samples recovered</strong>, 
                    bringing total accuracy to 90.4% (+5.3pp from baseline). However, loop-based 
                    decomposition risks token explosion, as 5 samples hit the 32K token limit.
                </p>

            </section>

            <!-- Section 5: Discussion & Conclusion -->
            <section id="conclusion">
                <h2>5. Discussion & Conclusion</h2>
                
                <p>
                    Transformer-based CWMs achieve strong baseline performance (85% on CruxEval, 
                    91% on HumanEval) by using dense state supervision (full state reveals at every step). This sidesteps the 
                    need for sophisticated state-tracking mechanisms: the model never needs to 
                    track state across more than one operation. However, this approach has clear 
                    limitations: nested expressions hide intermediates, causing super-linear accuracy 
                    degradation; string operations break token boundaries unpredictably; and long 
                    loops cause trace truncation for O(n¬≤) algorithms or large inputs.
                </p>

                <p>
                    The key insight is that <strong>expressivity is not learnability</strong>. 
                    When supervision becomes sparse‚Äîthrough composition, long loops, or tokenization 
                    artifacts‚Äîperformance degrades predictably. Future code world models will need 
                    architectures designed for state-tracking under realistic code complexity.
                </p>

                <div class="recommendations">
                    <h3>The Path Forward</h3>
                    <ol>
                        <li>
                            <strong>Hybrid architectures:</strong> Combine transformer's 
                            associative recall with linear RNN's state-tracking
                        </li>
                        <li>
                            <strong>Tokenization stability:</strong> Design tokenizers that 
                            maintain consistent boundaries across minor string edits
                        </li>
                    </ol>
                </div>
            </section>

            <!-- References -->
            <section id="references">
                <h2>References</h2>
                <ol class="references-list">
                    <li id="ref-genie">
                        Jake Bruce, Michael Dennis, Ashley Edwards, Jack Parker-Holder, Yuge Shi, Edward Hughes, 
                        Matthew Lai, Aditi Mavalankar, Richie Steigerwald, et al. 
                        <em>Genie: Generative Interactive Environments.</em> 2024. 
                        arXiv:<a href="https://arxiv.org/abs/2402.15391">2402.15391</a> [cs.LG].
                    </li>
                    <li id="ref-cwm">
                        FAIR CodeGen Team, Jade Copet, Quentin Carbonneaux, Gal Cohen, Jonas Gehring, Jacob Kahn, 
                        Jannik Kossen, Felix Kreuk, Emily McMilin, Michel Meyer, Yuxiang Wei, et al. 
                        <em>CWM: An Open-Weights LLM for Research on Code Generation with World Models.</em> 2025. 
                        arXiv:<a href="https://arxiv.org/abs/2510.02387">2510.02387</a> [cs.SE].
                    </li>
                    <li id="ref-plm">
                        Minsoo Kim, Yeonjoon Jung, Dohyeon Lee, Seung-won Hwang. 
                        <em>PLM-based World Models for Text-based Games.</em> 
                        EMNLP 2022, pp. 1324‚Äì1341.
                    </li>
                    <li id="ref-ggp">
                        Wolfgang Lehrach, Daniel Hennes, Miguel Lazaro-Gredilla, Xinghua Lou, Carter Wendelken, 
                        Zun Li, Antoine Dedieu, Jordi Grau-Moya, Marc Lanctot, Atil Iscen, et al. 
                        <em>Code World Models for General Game Playing.</em> 2025. 
                        arXiv:<a href="https://arxiv.org/abs/2510.04542">2510.04542</a>.
                    </li>
                    <li id="ref-mcts">
                        Nicola Dainese, Matteo Merler, Minttu Alakuijala, Pekka Marttinen. 
                        <em>Generating Code World Models with Large Language Models Guided by Monte Carlo Tree Search.</em> 
                        NeurIPS 2024, vol. 37, pp. 60429‚Äì60474.
                    </li>
                    <li id="ref-worldcoder">
                        Hao Tang, Darren Key, Kevin Ellis. 
                        <em>WorldCoder: A Model-Based LLM Agent for Building World Models by Writing Code and Interacting with the Environment.</em> 
                        NeurIPS 2024, vol. 37, pp. 70148‚Äì70212.
                    </li>
                    <li id="ref-merrill">
                        William Merrill, Ashish Sabharwal. 
                        <em>The Parallelism Tradeoff: Limitations of Log-Precision Transformers.</em> 
                        NeurIPS 2023. arXiv:<a href="https://arxiv.org/abs/2207.00729">2207.00729</a>.
                    </li>
                    <li id="ref-liu">
                        Bingbin Liu, Jordan T. Ash, Surbhi Goel, Akshay Krishnamurthy, Cyril Zhang. 
                        <em>Transformers Learn Shortcuts to Automata.</em> 
                        ICLR 2023. arXiv:<a href="https://arxiv.org/abs/2210.10749">2210.10749</a>.
                    </li>
                    <li id="ref-orvieto">
                        Antonio Orvieto, Samuel L. Smith, Albert Gu, Anushan Fernando, Caglar Gulcehre, 
                        Razvan Pascanu, Soham De. 
                        <em>Resurrecting Recurrent Neural Networks for Long Sequences.</em> 
                        ICML 2023. arXiv:<a href="https://arxiv.org/abs/2303.06349">2303.06349</a>.
                    </li>
                    <li id="ref-nesting">
                        Lifan Yuan, Weize Chen, Yuchen Zhang, Ganqu Cui, Hanbin Wang, Ziming You, 
                        Ning Ding, Zhiyuan Liu, Maosong Sun, Hao Peng. 
                        <em>From f(x) and g(x) to f(g(x)): LLMs Learn New Skills in RL by Composing Old Ones.</em> 
                        2025. arXiv:<a href="https://arxiv.org/abs/2509.25123">2509.25123</a>.
                    </li>
                    <li id="ref-cruxeval">
                        Alex Gu, Baptiste Rozi√®re, Hugh Leather, Armando Solar-Lezama, Gabriel Synnaeve, Sida I. Wang. 
                        <em>CruxEval: A Benchmark for Code Reasoning, Understanding and Execution.</em> 
                        2024. arXiv:<a href="https://arxiv.org/abs/2401.03065">2401.03065</a>.
                    </li>
                    <li id="ref-humaneval">
                        Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, 
                        Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. 
                        <em>Evaluating Large Language Models Trained on Code.</em> 
                        2021. arXiv:<a href="https://arxiv.org/abs/2107.03374">2107.03374</a>.
                    </li>
                </ol>
            </section>

            <!-- Resources -->
            <section id="resources">
                <h2>Resources</h2>
                <ul>
                    <li><a href="#">Paper (coming soon)</a></li>
                    <li><a href="#">Code & Data</a></li>
                </ul>
            </section>

            <!-- Citation -->
            <section id="citation">
                <h2>Citation</h2>
                <div class="citation-box">
<pre>@article{authors2026statetracking,
  title={Understanding State-Tracking in Linear RNNs for Code Execution},
  author={...},
  journal={ICLR},
  year={2026}
}</pre>
                </div>
            </section>

        </article>
    </main>

    <footer>
        <p>&copy; 2026 Research Blog. All rights reserved.</p>
    </footer>
</body>
</html>
